## Домашняя работа 2

Написать приложение на Scala, которое будет выполнять следующее:

Очищать данные из папки ```/stage``` и складывать их в папку ```/ods``` в корне HDFS по следующим правилам:

1. Структура партиций (папок вида date=...) должна сохраниться.
2. Внутри папок должен остаться только один файл, содержащий все данные файлов из соответствующей партиции в папке ```/stage```.

То есть, если у нас есть папка ```/stage/date=2020-11-11``` с файлами

```
part-0000.csv
part-0001.csv
```

то должна получиться папка ```/ods/date=2020-11-11``` с одним файлом
```
part-0000.csv
```

содержащим все данные из файлов папки ```/stage/date=2020-11-11.```

### Сборка и запуск приложения:

* Из проекта запустить
```
docker-compose up -d
```

* Прописать /etc/hosts
```
127.0.0.1 namenode
127.0.0.1 datanode
```

* Закинуть данные в папку ```/stage```
```
docker exec namenode hdfs dfs -put /sample_data/stage /
```

* Собрать executable jar в папке с проектом `sbt assembly`


* Пример запуска:
```
scala hw2_hdfs-assembly-{VERSION}.jar
```